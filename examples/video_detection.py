"""
è§†é¢‘æ£€æµ‹ç¤ºä¾‹ - å®Œæ•´åŠŸèƒ½ç‰ˆ
ä½¿ç”¨GSEæ£€æµ‹å™¨å¤„ç†è§†é¢‘æ–‡ä»¶æˆ–æ‘„åƒå¤´
æ”¯æŒé«˜åˆ†è¾¨ç‡ã€ByteTrackè·Ÿè¸ªã€ç•¸å˜çŸ«æ­£ç­‰åŠŸèƒ½

ä½¿ç”¨æ–¹æ³•:
    # åŸºç¡€ä½¿ç”¨ï¼ˆé»˜è®¤2560x1440@60fps, å¸¦è·Ÿè¸ªï¼‰
    python video_detection.py 0 --enable-tracking --device cuda
    
    # è‡ªå®šä¹‰åˆ†è¾¨ç‡
    python video_detection.py 0 --width 1920 --height 1080 --fps 60
    
    # å¯ç”¨ç•¸å˜çŸ«æ­£
    python video_detection.py 0 --enable-tracking --undistort
"""

import cv2
import sys
import time
import argparse
import yaml
import numpy as np
from pathlib import Path
from collections import deque
from typing import Dict, Tuple, Optional

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from detector import GSEDetector
from byte_tracker import BYTETracker
from camera_io import CameraConfig, open_camera, get_actual_capture_params


def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    p = argparse.ArgumentParser(description="GSEæ£€æµ‹ - å®Œæ•´åŠŸèƒ½ç‰ˆ")
    
    # è§†é¢‘æº
    p.add_argument("source", nargs="?", default="0",
                   help="è§†é¢‘æºï¼šæ‘„åƒå¤´ID(å¦‚0)æˆ–è§†é¢‘æ–‡ä»¶è·¯å¾„")
    
    # æ¨¡å‹å‚æ•°
    p.add_argument("--device", type=str, default="cuda",
                   choices=["cuda", "cpu"],
                   help="æ¨ç†è®¾å¤‡")
    p.add_argument("--conf", type=float, default=0.25,
                   help="ç½®ä¿¡åº¦é˜ˆå€¼")
    p.add_argument("--model-size", type=int, default=1280,
                   help="YOLOæ¨ç†å°ºå¯¸")
    
    # æ‘„åƒå¤´å‚æ•°ï¼ˆä»…å½“sourceä¸ºæ‘„åƒå¤´IDæ—¶æœ‰æ•ˆï¼‰
    p.add_argument("--width", type=int, default=2560,
                   help="ç›¸æœºå®½åº¦")
    p.add_argument("--height", type=int, default=1440,
                   help="ç›¸æœºé«˜åº¦")
    p.add_argument("--fps", type=int, default=60,
                   help="ç›¸æœºå¸§ç‡")
    p.add_argument("--backend", type=str, default="dshow",
                   choices=["dshow", "msmf", "any"],
                   help="OpenCVåç«¯ï¼ˆWindowsæ¨èdshowï¼‰")
    p.add_argument("--fourcc", type=str, default="MJPG",
                   help="ç›¸æœºåƒç´ æ ¼å¼")
    p.add_argument("--buffersize", type=int, default=1,
                   help="é‡‡é›†ç¼“å†²åŒºå¤§å°")
    
    # è·Ÿè¸ªå‚æ•°
    p.add_argument("--enable-tracking", action="store_true",
                   help="å¯ç”¨ByteTrackå¤šç›®æ ‡è·Ÿè¸ª")
    p.add_argument("--track-thresh", type=float, default=0.5,
                   help="é«˜ç½®ä¿¡åº¦æ£€æµ‹é˜ˆå€¼")
    p.add_argument("--track-buffer", type=int, default=30,
                   help="è½¨è¿¹ç¼“å†²å¸§æ•°")
    p.add_argument("--match-thresh", type=float, default=0.8,
                   help="åŒ¹é…IoUé˜ˆå€¼")
    
    # ç•¸å˜çŸ«æ­£
    p.add_argument("--undistort", action="store_true",
                   help="å¯ç”¨ç•¸å˜çŸ«æ­£")
    p.add_argument("--calib-config", type=str,
                   default="../tools/config/camera_calibration.yaml",
                   help="æ ‡å®šæ–‡ä»¶è·¯å¾„")
    
    return p.parse_args()


def load_camera_calibration(config_path: str) -> Tuple[Optional[np.ndarray], Optional[np.ndarray]]:
    """åŠ è½½ç›¸æœºæ ‡å®šå‚æ•°"""
    config_path = Path(__file__).parent.parent.parent / "tools" / "config" / "camera_calibration.yaml"
    
    if not config_path.exists():
        print(f"âš ï¸  æ ‡å®šæ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        return None, None
    
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            data = yaml.safe_load(f)
        
        camera_matrix = np.array(data['camera_matrix'])
        dist_coeffs = np.array(data['distortion_coefficients'])
        
        print(f"âœ… å·²åŠ è½½æ ‡å®šå‚æ•°")
        return camera_matrix, dist_coeffs
    except Exception as e:
        print(f"âŒ åŠ è½½æ ‡å®šå‚æ•°å¤±è´¥: {e}")
        return None, None


def draw_tracking_results(frame: np.ndarray, tracks: list, class_names: dict, conf_thresh: float = 0.25):
    """ç»˜åˆ¶è·Ÿè¸ªç»“æœ"""
    for track in tracks:
        x1, y1, x2, y2 = map(int, track.tlbr)
        track_id = track.track_id
        score = track.score
        cls = int(track.cls)
        
        if score < conf_thresh:
            continue
        
        class_name = class_names.get(cls, f"class_{cls}")
        
        # è·å–é¢œè‰²
        from config import CLASS_COLORS
        color = CLASS_COLORS.get(cls, (0, 255, 255))
        
        # ç»˜åˆ¶è¾¹æ¡†
        cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
        
        # ç»˜åˆ¶æ ‡ç­¾
        label = f"ID:{track_id} {class_name} {score:.2f}"
        
        text_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]
        bg_x1, bg_y1 = x1, max(0, y1 - text_size[1] - 10)
        bg_x2, bg_y2 = x1 + text_size[0] + 10, y1
        
        cv2.rectangle(frame, (bg_x1, bg_y1), (bg_x2, bg_y2), color, -1)
        cv2.putText(frame, label, (x1 + 5, y1 - 5), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)


def main():
    args = parse_args()
    
    print("=" * 70)
    print("ğŸš€ GSEæ£€æµ‹ç³»ç»Ÿ - å®Œæ•´åŠŸèƒ½ç‰ˆ")
    print("=" * 70)
    
    # åˆ¤æ–­æ˜¯æ‘„åƒå¤´è¿˜æ˜¯è§†é¢‘æ–‡ä»¶
    try:
        camera_id = int(args.source)
        is_camera = True
        print(f"ğŸ“· ä½¿ç”¨æ‘„åƒå¤´ {camera_id}")
    except ValueError:
        is_camera = False
        print(f"ğŸ“¹ ä½¿ç”¨è§†é¢‘æ–‡ä»¶: {args.source}")
    
    # æ‰“å¼€è§†é¢‘æº
    if is_camera:
        cap_cfg = CameraConfig(
            camera_id=camera_id,
            width=args.width,
            height=args.height,
            fps=args.fps,
            backend=args.backend,
            fourcc=args.fourcc,
            buffersize=args.buffersize
        )
        cap = open_camera(cap_cfg)
        if cap.isOpened():
            actual = get_actual_capture_params(cap)
            print(f"âœ… ç›¸æœºå·²æ‰“å¼€: {actual['width']}x{actual['height']} @ {actual['fps']:.1f}FPS (FOURCC={args.fourcc})")
    else:
        cap = cv2.VideoCapture(args.source)
        if cap.isOpened():
            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            fps = cap.get(cv2.CAP_PROP_FPS)
            print(f"âœ… è§†é¢‘å·²æ‰“å¼€: {width}x{height} @ {fps:.1f}FPS")
    
    if not cap.isOpened():
        print(f"âŒ æ— æ³•æ‰“å¼€è§†é¢‘æº")
        return
    
    # åˆå§‹åŒ–æ£€æµ‹å™¨
    print("\nåˆå§‹åŒ–æ£€æµ‹å™¨...")
    detector = GSEDetector(
        device=args.device,
        conf_threshold=args.conf,
        input_size=args.model_size
    )
    
    # åˆå§‹åŒ–ByteTrackè·Ÿè¸ªå™¨
    tracker = None
    if args.enable_tracking:
        tracker = BYTETracker(
            track_thresh=args.track_thresh,
            track_buffer=args.track_buffer,
            match_thresh=args.match_thresh,
            frame_rate=args.fps
        )
        print(f"âœ… ByteTrackå·²åˆå§‹åŒ– (thresh={args.track_thresh}, buffer={args.track_buffer})")
    
    # åŠ è½½ç•¸å˜çŸ«æ­£å‚æ•°
    camera_matrix, dist_coeffs = None, None
    undistort_enabled = args.undistort
    if undistort_enabled:
        camera_matrix, dist_coeffs = load_camera_calibration(args.calib_config)
    
    # FPSè®¡ç®—
    fps_queue = deque(maxlen=30)
    frame_count = 0
    map1, map2 = None, None
    
    print("\næŒ‰é”®è¯´æ˜:")
    print("  Q - é€€å‡º")
    print("  S - ä¿å­˜å½“å‰å¸§")
    print("  U - åˆ‡æ¢ç•¸å˜çŸ«æ­£")
    if tracker:
        print("  T - åˆ‡æ¢è·Ÿè¸ª")
    print("-" * 70)
    
    tracking_enabled = args.enable_tracking
    
    try:
        while True:
            start_time = time.time()
            
            # è¯»å–å¸§
            ret, frame = cap.read()
            if not ret:
                print("è§†é¢‘ç»“æŸæˆ–è¯»å–å¤±è´¥")
                break
            
            frame_count += 1
            h, w = frame.shape[:2]
            
            # ç•¸å˜çŸ«æ­£
            if undistort_enabled and camera_matrix is not None:
                if map1 is None or map2 is None:
                    new_camera_matrix, _roi = cv2.getOptimalNewCameraMatrix(
                        camera_matrix, dist_coeffs, (w, h), 1, (w, h)
                    )
                    map1, map2 = cv2.initUndistortRectifyMap(
                        camera_matrix, dist_coeffs, None, new_camera_matrix, (w, h), cv2.CV_16SC2
                    )
                frame = cv2.remap(frame, map1, map2, cv2.INTER_LINEAR)
            
            # æ‰§è¡Œæ£€æµ‹
            if tracking_enabled and tracker:
                # ä½¿ç”¨è·Ÿè¸ªæ¨¡å¼
                raw_results = detector.detect(frame, return_raw=True)
                
                # è½¬æ¢ä¸ºByteTrackæ ¼å¼ [x1, y1, x2, y2, score, class]
                det_list = []
                if len(raw_results) > 0 and raw_results[0].boxes is not None:
                    boxes = raw_results[0].boxes
                    if len(boxes) > 0:
                        xyxy = boxes.xyxy.cpu().numpy()
                        confs = boxes.conf.cpu().numpy()
                        clss = boxes.cls.cpu().numpy()
                        det_list = np.concatenate([xyxy, confs[:, None], clss[:, None]], axis=1)
                
                detections_np = np.array(det_list) if len(det_list) > 0 else np.empty((0, 6))
                tracks = tracker.update(detections_np)
                
                # ç»˜åˆ¶è·Ÿè¸ªç»“æœ
                result_frame = frame.copy()
                draw_tracking_results(result_frame, tracks, detector.class_names, args.conf)
                num_objects = len(tracks)
            else:
                # ä»…æ£€æµ‹æ¨¡å¼
                detections = detector.detect(frame)
                result_frame = detector.draw_results(frame, detections)
                num_objects = len(detections)
            
            # è®¡ç®—FPS
            elapsed = time.time() - start_time
            fps_queue.append(1.0 / elapsed if elapsed > 0 else 0)
            current_fps = sum(fps_queue) / len(fps_queue)
            
            # æ˜¾ç¤ºä¿¡æ¯
            info_lines = [
                f"FPS: {current_fps:.1f}",
                f"Objects: {num_objects}",
                f"Resolution: {w}x{h}",
                f"Undistort: {'ON' if undistort_enabled else 'OFF'}",
                f"Tracking: {'ON' if tracking_enabled else 'OFF'}",
                f"Device: {args.device.upper()}"
            ]
            
            y_offset = 30
            for line in info_lines:
                cv2.putText(result_frame, line, (10, y_offset),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                y_offset += 30
            
            # è‡ªåŠ¨ç¼©æ”¾æ˜¾ç¤ºï¼ˆå¦‚æœåˆ†è¾¨ç‡è¶…è¿‡1920x1080ï¼‰
            display_frame = result_frame
            if w > 1920 or h > 1080:
                scale = min(1920/w, 1080/h)
                display_w = int(w * scale)
                display_h = int(h * scale)
                display_frame = cv2.resize(result_frame, (display_w, display_h))
            
            # æ˜¾ç¤ºç»“æœ
            cv2.imshow("GSE Detection (Q:Quit, S:Save, U:Undistort, T:Tracking)", display_frame)
            
            # æŒ‰é”®å¤„ç†
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q') or key == ord('Q'):
                print("\né€€å‡º...")
                break
            elif key == ord('s') or key == ord('S'):
                filename = f"frame_{frame_count:06d}.jpg"
                cv2.imwrite(filename, result_frame)
                print(f"ğŸ’¾ å·²ä¿å­˜: {filename}")
            elif key == ord('u') or key == ord('U'):
                if camera_matrix is not None:
                    undistort_enabled = not undistort_enabled
                    map1, map2 = None, None  # é‡ç½®æ˜ å°„
                    print(f"ğŸ”„ ç•¸å˜çŸ«æ­£: {'å¯ç”¨' if undistort_enabled else 'ç¦ç”¨'}")
                else:
                    print("âš ï¸  æœªåŠ è½½æ ‡å®šå‚æ•°")
            elif key == ord('t') or key == ord('T'):
                if tracker:
                    tracking_enabled = not tracking_enabled
                    if not tracking_enabled:
                        tracker.reset()
                    print(f"ğŸ¯ è·Ÿè¸ª: {'å¯ç”¨' if tracking_enabled else 'ç¦ç”¨'}")
    
    except KeyboardInterrupt:
        print("\nğŸ›‘ ç¨‹åºä¸­æ–­")
    
    finally:
        cap.release()
        cv2.destroyAllWindows()
        
        print("\n" + "=" * 70)
        print("ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
        print(f"  æ€»å¸§æ•°: {frame_count}")
        print(f"  å¹³å‡FPS: {sum(fps_queue)/len(fps_queue):.2f}" if fps_queue else "  å¹³å‡FPS: N/A")
        if tracker:
            print(f"  æ€»è½¨è¿¹æ•°: {tracker.track_id_count}")
        print("=" * 70)
        print("âœ… ç¨‹åºç»“æŸ")


if __name__ == "__main__":
    main()
